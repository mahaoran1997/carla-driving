{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./drive_interfaces/carla/carla_client/\")\n",
    "from carla.client import make_carla_client\n",
    "from carla.settings import CarlaSettings\n",
    "from carla.client import VehicleControl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"./drive_interfaces/carla/yang_template.ini\", \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from carla.sensor import Camera, Lidar\n",
    "settings = CarlaSettings()\n",
    "settings.set(\n",
    "    SynchronousMode=True,\n",
    "    SendNonPlayerAgentsInfo=True,\n",
    "    NumberOfVehicles=20,\n",
    "    NumberOfPedestrians=40,\n",
    "    WeatherId=random.choice([1, 3, 7, 8, 14]),\n",
    "    QualityLevel=\"Low\")\n",
    "settings.randomize_seeds()\n",
    "\n",
    "# Now we want to add a couple of cameras to the player vehicle.\n",
    "# We will collect the images produced by these cameras every\n",
    "# frame.\n",
    "\n",
    "# The default camera captures RGB images of the scene.\n",
    "camera0 = Camera('CameraRGB')\n",
    "# Set image resolution in pixels.\n",
    "camera0.set_image_size(800, 600)\n",
    "# Set its position relative to the car in meters.\n",
    "camera0.set_position(0.30, 0, 1.30)\n",
    "settings.add_sensor(camera0)\n",
    "\n",
    "# Let's add another camera producing ground-truth depth.\n",
    "camera1 = Camera('CameraDepth', PostProcessing='Depth')\n",
    "camera1.set_image_size(800, 600)\n",
    "camera1.set_position(0.30, 0, 1.30)\n",
    "settings.add_sensor(camera1)\n",
    "\n",
    "print(str(settings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from carla.client import CarlaClient\n",
    "client = CarlaClient(\"127.0.0.1\", 2000)\n",
    "client.connect()\n",
    "with open(\"./drive_interfaces/carla/yang_template.ini\", \"r\") as f:\n",
    "    #client.load_settings(settings)\n",
    "    client.load_settings(f.read())\n",
    "client.start_episode(0)\n",
    "measurements, sensor_data = client.read_data()\n",
    "client.send_control(VehicleControl())\n",
    "\n",
    "client.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with make_carla_client(\"127.0.0.1\", 2000) as client:\n",
    "    with open(\"./drive_interfaces/carla/yang_template.ini\", \"r\") as f:\n",
    "        #client.load_settings(settings)\n",
    "        client.load_settings(f.read())\n",
    "    client.start_episode(0)\n",
    "    measurements, sensor_data = client.read_data()\n",
    "    client.send_control(VehicleControl())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "measurements.player_measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sensor_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_converter.depth_to_array(sensor_data['DepthLeft']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=image_converter.labels_to_array(sensor_data['SegLeft'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "b=a[:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "image = scipy.misc.imresize(b, [30, 40], interp='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=sensor_data['DepthLeft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from carla import image_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b=image_converter.depth_to_array(a)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "measure, sensor ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path= \"/scratch/yang/aws_data/carla_collect/1/2018726_default_RotationPitch=-15_WeatherId=10_4/data_00000.h5\"\n",
    "import h5py\n",
    "f=h5py.File(path, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imdecode(f['CameraLeft'][0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "a=Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path= \"/scratch/yang/aws_data/carla_collect/1/2018726_default_RotationPitch=-15_WeatherId=10_5/data_00000.h5\"\n",
    "path = \"/data/yang/code/aws/scratch/carla_collect/1/2018727_default_RotationPitch=0_WeatherId=13_1/data_00000.h5\"\n",
    "path = \"/scratch/yang/aws_data/carla_collect/1/2018730_default_RotationPitch=0_WeatherId=01_1/data_00000.h5\"\n",
    "def sample_images_from_h5(path):\n",
    "    f=h5py.File(path, \"r\")\n",
    "    for key in f.keys():\n",
    "        if 'targets' not in key:\n",
    "            for imid in range(200):\n",
    "                data = f[key][imid]\n",
    "                if 'camera' in key.lower():\n",
    "                    ext = \".jpg\"\n",
    "                else:\n",
    "                    ext = \".png\"\n",
    "                out_name = path+\".\" + key + str(imid).zfill(4) + ext\n",
    "                with open(out_name, \"w\") as g:\n",
    "                    g.write(data)\n",
    "sample_images_from_h5(path)\n",
    "\n",
    "\"ffmpeg -i data_00000.h5.CameraMiddle%04d.png -c:v libx264 out.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "for i in range(1):\n",
    "    prefix = \"/scratch/yang/aws_data/carla_collect/1/2018730_default_RotationPitch=0_WeatherId=\"+str(i).zfill(2)+\"_1/\"\n",
    "    path = prefix + \"data_00000.h5\"\n",
    "    ! ls -alh $path\n",
    "    sample_images_from_h5(path)\n",
    "    \n",
    "    call(\"ffmpeg -i \"+ prefix +\"data_00000.h5.CameraMiddle%04d.jpg -c:v libx264 \"+ prefix[:-1]+\".mp4\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "from multiprocessing import Process\n",
    "import time\n",
    "\n",
    "class ControlInterface(object):\n",
    "    def __init__(self):\n",
    "        self._throttle = 1.0       \n",
    "        self.counter = 0        \n",
    "        self.start_loop()\n",
    "        self.last_time = time.time()\n",
    "\n",
    "    def set_throttle(self, new_throttle):\n",
    "        self._throttle = new_throttle\n",
    "\n",
    "    def start_loop(self):\n",
    "        self.counter += 1\n",
    "        if self.counter % 75 == 0:\n",
    "            print(\"time eplapsed is \", time.time()-self.last_time)\n",
    "            self.last_time = time.time()\n",
    "            print( \"throttle\", self._throttle)\n",
    "        threading.Timer(1.0/75, self.start_loop).start()\n",
    "        \n",
    "\n",
    "ctrl = ControlInterface()\n",
    "print(\"after constructor\")\n",
    "ctrl.set_throttle(-1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def get_files_count_in_folder(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        return 0\n",
    "    else:\n",
    "        pass\n",
    "import glob\n",
    "len(glob.glob(\"/data/yang/code/aws/scratch/carla_collect/1/2018731_default_RotationPitch=0_WeatherId=01_1/*.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, threading\n",
    "cmd = ['bash', '-c', \" '/scratch/yang/aws_data/carla_0.8.4/CarlaUE4.sh  -carla-server -carla-settings=/data/yang/code/aws/CIL_modular/drive_interfaces/carla/yang_template.ini -benchmark -fps=5' \"]\n",
    "#cmd = cmd.split(\" \")\n",
    "#cmd = [x for x in cmd if x!=\"\" ]\n",
    "print(\" \".join(cmd))\n",
    "print(\"before spawnling\")\n",
    "t = threading.Thread(target = lambda : os.system(\" \".join(cmd)))\n",
    "t.start()       \n",
    "#! ps aux | grep $id0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(glob.glob(\"/data/yang/code/aws/scratch/carla_collect/1/*/data_*.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"/scratch/yang/aws_data/CIL_modular_data/matthias_data/RC025Val/data_00000.h5\"\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=h5py.File(path, \"r\")\n",
    "\n",
    "a=f['rgb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "i+=3\n",
    "print(i)\n",
    "Image.fromarray(a[i, :,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path =\"/scratch/yang/aws_data/carla_collect/1/default_ImageSizeX=700_WeatherId=10/data_00099.h5\"\n",
    "import h5py, time\n",
    "f = h5py.File(path, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "start = time.time()\n",
    "t_decode = 0.0\n",
    "t_resize = 0.0\n",
    "for i in range(200):\n",
    "    a= f[\"CameraMiddle\"][i]\n",
    "    start = time.time()\n",
    "    decoded = cv2.imdecode(a, 1)                    \n",
    "    t_decode += time.time()-start\n",
    "    sz = (88,200)\n",
    "    start = time.time()\n",
    "    decoded = cv2.resize(decoded, (sz[1], sz[0]))\n",
    "    t_resize += time.time() -start\n",
    "delta = time.time()-start\n",
    "print(delta, 200/delta)\n",
    "print(t_decode, t_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "91*20*200 /1000/1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "8*75/1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "p = Parallel(n_jobs=8, backend=\"threading\", verbose=10)\n",
    "\n",
    "\n",
    "func = lambda x : cv2.imdecode(x, 1)\n",
    "if True:\n",
    "    height, width = 88, 200\n",
    "    func_previous = func\n",
    "    func = lambda x : cv2.resize(func_previous(x), (width, height))\n",
    "                \n",
    "func = lambda x : cv2.resize(cv2.imdecode(x, 1), (200, 88))        \n",
    "func = delayed(func)\n",
    "results = p(func(f[\"CameraMiddle\"][0]) for i in range(8*75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = p(delayed(cv2.imdecode)(f[\"CameraMiddle\"][i], 1) for i in range(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.fromarray(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.concatenate((results[0], results[0]+5), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b=cv2.resize(a, (200, 300))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image.fromarray(b[:,:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def _resize_BHWC(input, sz):\n",
    "    B, H, W, C = input.shape\n",
    "    input = np.transpose(input, (1, 2, 3, 0))\n",
    "    # now input has size H W C B\n",
    "    input = np.reshape(input, (H, W, C*B))\n",
    "    print(input.shape)\n",
    "    output = cv2.resize(input[:,:,:1000], (sz[1], sz[0]))\n",
    "    output = np.reshape(output, (sz[0], sz[1], C, B))\n",
    "    output = np.transpose(output, (3, 0, 1, 2))\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stk = np.stack(results, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = _resize_BHWC(stk, (200, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "func = lambda x: cv2.imdecode(x, 1)\n",
    "if hasattr(self._config, \"hack_resize_image\"):\n",
    "    height, width = self._config.hack_resize_image\n",
    "    func_previous = func\n",
    "    func = lambda x: cv2.resize(func_previous(x), (width, height))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# measure the segmentation difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"/scratch/yang/aws_data/carla_collect/10/default_PositionZ=1.4_WeatherId=03/data_00000.h5\"\n",
    "import h5py\n",
    "f = h5py.File(path, \"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "for i in range(200):\n",
    "    image = f['CameraMiddle'][i]\n",
    "    image = cv2.imdecode(image, 1)\n",
    "    image = image[:,:, ::-1]\n",
    "    seg = f['SegMiddle'][i]\n",
    "    seg = cv2.imdecode(seg, 0)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0\tNone\n",
    "1\tBuildings\n",
    "2\tFences\n",
    "3\tOther\n",
    "4\tPedestrians\n",
    "5\tPoles\n",
    "6\tRoadLines\n",
    "7\tRoads\n",
    "8\tSidewalks\n",
    "9\tVegetation\n",
    "10\tVehicles\n",
    "11\tWalls\n",
    "12\tTrafficSigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0          1            2           3               4               5      6\n",
    "{'Ignored', 'Movable', 'Navigable', 'NoneNavigable', 'StaticLayout', 'Sky', 'Lane'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mapping = np.array([0, 4, 3, 0, 1, 4, 6, 2, 3, 4, 1, 4, 4])\n",
    "seg_cvt = mapping[seg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/data/yang/code/aws\")\n",
    "from all_perceptions import Perceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = Perceptions(det_COCO=False,\n",
    "                 det_TL=False,\n",
    "                 det_TS=False,\n",
    "                 seg=True,\n",
    "                 depth=False,\n",
    "                 batch_size=1, # batch_size could also be a dict\n",
    "                 gpu_assignment=[0],\n",
    "                 compute_methods={},\n",
    "                 viz_methods={},\n",
    "                 num_replicates={},\n",
    "                 path_config=\"path_jormungandr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_batch = np.expand_dims(image, 0)\n",
    "out = p.compute(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = np.squeeze(out['seg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = np.argmax(out, axis=2) + 1 # 0 does not exists, since it is the ignore class underhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = cv2.resize(out, (out.shape[1]*4, out.shape[0]*4), interpolation=cv2.INTER_NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sky is ignored, also the ignore class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image.fromarray((out==1).astype(np.uint8)*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Image.fromarray((seg_cvt==1).astype(np.uint8)*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_inter_union(gt, pred, nclasses):\n",
    "    # return a nclass * 2 matrix: [iclass][inter, union]\n",
    "    out = np.zeros((nclasses, 2), dtype=np.int64)\n",
    "    pred = pred[gt!=0] - 1 \n",
    "    gt = gt[gt!=0] - 1\n",
    "    for i in range(nclasses):\n",
    "        out[i, 0] = np.sum(np.logical_and(pred == i, gt == i))\n",
    "        out[i, 1] = np.sum(np.logical_or (pred == i, gt == i))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_inter_union(seg_cvt, out, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../seg.pkl\", \"r\") as f:\n",
    "    res = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perf.focal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py, cv2, sys, pickle, math, numpy\n",
    "import numpy as np\n",
    "sys.path.append(\"/data/yang/code/aws\")\n",
    "from all_perceptions import Perceptions\n",
    "\n",
    "debug = None\n",
    "\n",
    "class DepthPerformance():\n",
    "    def __init__(self):\n",
    "        width = 768\n",
    "        fov = 90.0\n",
    "        self.focal = width / (2.0 * math.tan(fov * math.pi / 360.0))\n",
    "        self.baseline = 0.54\n",
    "\n",
    "        self.p = Perceptions(det_COCO=False,\n",
    "                             det_TL=False,\n",
    "                             det_TS=False,\n",
    "                             seg=False,\n",
    "                             depth=True,\n",
    "                             batch_size=1,  # batch_size could also be a dict\n",
    "                             gpu_assignment=[0],\n",
    "                             compute_methods={},\n",
    "                             viz_methods={},\n",
    "                             num_replicates={},\n",
    "                             path_config=\"path_jormungandr\")\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def _compute_errors(self, gt, pred):\n",
    "        thresh = np.maximum((gt / pred), (pred / gt))\n",
    "        a1 = (thresh < 1.25).mean()\n",
    "        a2 = (thresh < 1.25 ** 2).mean()\n",
    "        a3 = (thresh < 1.25 ** 3).mean()\n",
    "\n",
    "        rmse = (gt - pred) ** 2\n",
    "        rmse = np.sqrt(rmse.mean())\n",
    "\n",
    "        rmse_log = (np.log(gt) - np.log(pred)) ** 2\n",
    "        rmse_log = np.sqrt(rmse_log.mean())\n",
    "\n",
    "        abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
    "\n",
    "        sq_rel = np.mean(((gt - pred) ** 2) / gt)\n",
    "\n",
    "        return abs_rel, sq_rel, rmse, rmse_log, a1, a2, a3\n",
    "\n",
    "    def reset(self):\n",
    "        self.accu = []\n",
    "        self.count = 0\n",
    "\n",
    "    def one_pair(self, image, depth):\n",
    "        image_batch = np.expand_dims(image, 0)\n",
    "        out = self.p.compute(image_batch)\n",
    "        out = np.squeeze(out['depth'])\n",
    "        out = cv2.resize(out, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        out = self.baseline * self.focal / (out + 0.0000001)\n",
    "        out = out / 800.0 # some magic number that I made up \n",
    "        global debug \n",
    "        debug = out\n",
    "\n",
    "        errors = self._compute_errors(depth+1e-5, out+1e-5)\n",
    "        self.accu.append(errors)\n",
    "        self.count += 1\n",
    "\n",
    "    def summarize(self):\n",
    "        names = ['abs_rel', 'sq_rel', 'rmse', 'rmse_log', 'a1', 'a2', 'a3']\n",
    "        errors = np.stack(self.accu, axis=0)\n",
    "        errors = np.mean(errors, 0)\n",
    "        out = {}\n",
    "        for i in range(len(names)):\n",
    "            out[names[i]] = errors[i]\n",
    "        return out\n",
    "\n",
    "\n",
    "modality = \"depth\" # \"seg\"\n",
    "\n",
    "perf = {\"depth\": DepthPerformance, \"seg\":None}[modality]()\n",
    "results = {}\n",
    "#for town in [\"Town01\", \"Town02\"]:\n",
    "for town in [\"Town02\"]:\n",
    "    results[town] = {}\n",
    "    for weather in range(1, 14):\n",
    "        perf.reset()\n",
    "        path = \"/scratch/yang/aws_data/carla_collect/\"+town + \"_allsensor/default_RotationPitch=0_WeatherId=\" +str(weather).zfill(2) + \"/data_00000.h5\"\n",
    "        f = h5py.File(path, \"r\")\n",
    "        for i in range(200):\n",
    "            #print(i)\n",
    "            image = f['CameraMiddle'][i]\n",
    "            image = cv2.imdecode(image, 1)\n",
    "            image = image[:,:, ::-1]\n",
    "\n",
    "            if modality == \"seg\":\n",
    "                seg = f['SegMiddle'][i]\n",
    "                mode_image = cv2.imdecode(seg, 0)\n",
    "            elif modality == \"depth\":\n",
    "                mode_image = f['DepthMiddle'][i]\n",
    "                mode_image = cv2.imdecode(mode_image, 1)\n",
    "                # TODO: convert it\n",
    "                def to_depth(array):\n",
    "                    # input is bgr\n",
    "                    array = array.astype(numpy.float32)\n",
    "                    # Apply (R + G * 256 + B * 256 * 256) / (256 * 256 * 256 - 1).\n",
    "                    normalized_depth = numpy.dot(array[:, :, :], [65536.0, 256.0, 1.0])\n",
    "                    normalized_depth /= 16777215.0 / 1000.0  # (256.0 * 256.0 * 256.0 - 1.0)\n",
    "                    return normalized_depth\n",
    "                mode_image = to_depth(mode_image)\n",
    "            else:\n",
    "                raise\n",
    "            \n",
    "            perf.reset()\n",
    "            perf.one_pair(image, mode_image)\n",
    "            print(perf.summarize())\n",
    "            raise\n",
    "            break\n",
    "        f.close()\n",
    "        print(town, \"weather\", weather, perf.summarize())\n",
    "        results[town][weather] = perf.summarize()\n",
    "        with open(modality + \".pkl\", \"w\") as ppp:\n",
    "            pickle.dump(results, ppp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mode_image.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(mode_image[:,:,0]==mode_image[:,:,2]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.histogram(mode_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_gray(normalized_depth):\n",
    "    normalized_depth = normalized_depth /1000.0\n",
    "    logdepth = numpy.ones(normalized_depth.shape) + \\\n",
    "        (numpy.log(normalized_depth) / 5.70378)\n",
    "    logdepth = numpy.clip(logdepth, 0.0, 1.0)\n",
    "    logdepth *= 255.0\n",
    "    logdepth = np.uint8(logdepth)\n",
    "    # Expand to three colors.\n",
    "    return numpy.repeat(logdepth[:, :, numpy.newaxis], 3, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d=to_gray(mode_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mode_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Image.fromarray(to_gray(mode_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.histogram(debug/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "84642.0 / mode_image.size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.histogram(mode_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image.fromarray(to_gray(debug/3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# covnert matthias data to my format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"/scratch/yang/aws_data/CIL_modular_data/matthias_data/RC28_wpz_M/data_00000.h5\"\n",
    "import h5py\n",
    "f=h5py.File(path, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'depth', u'labels', u'rgb', u'targets']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 88, 200, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['rgb'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = \"/scratch/yang/aws_data/carla_collect/matthias_converted/train/data_00000.h5\"\n",
    "hf=h5py.File(out, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_rewards = hf.create_dataset('targets', (200, 35), 'f')\n",
    "dt = h5py.special_dtype(vlen=np.dtype('uint8'))\n",
    "sensor = hf.create_dataset(\"CameraMiddle\", (200,), dtype=dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yang/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:5: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    }
   ],
   "source": [
    "import cv2, math\n",
    "for i in range(200):\n",
    "    image = f['rgb'][i]\n",
    "    image = cv2.imencode(\".jpg\", image)[1]\n",
    "    encoded = np.fromstring(image, dtype=np.uint8)\n",
    "    sensor[i] = encoded\n",
    "    \n",
    "    line = f[\"targets\"][i]\n",
    "    # change speed\n",
    "    speed_kmh = line[10]\n",
    "    line[10] /= 3.6\n",
    "    # augment steer\n",
    "    angle = math.radians(30.0)\n",
    "    time_use = 1.0\n",
    "    car_lenght = 6.0\n",
    "    delta = min(6 * (math.atan((angle * car_lenght) / (time_use * speed_kmh + 0.05))) / math.pi, 0.3)\n",
    "    line[0] -= np.sign(line[26])*delta\n",
    "    \n",
    "    data_rewards[i, :] = line\n",
    "\n",
    "hf.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sign(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Not a location id (Invalid object id)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8971b5f4a74e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/yang/anaconda2/lib/python2.7/site-packages/h5py/_hl/base.pyc\u001b[0m in \u001b[0;36mkeys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;34m\"\"\" Get a list containing member names \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1496871545397/work/h5py/_objects.c:2846)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1496871545397/work/h5py/_objects.c:2804)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/yang/anaconda2/lib/python2.7/site-packages/h5py/_hl/group.pyc\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;34m\"\"\" Number of members attached to this group \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwith_phil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1496871545397/work/h5py/_objects.c:2846)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1496871545397/work/h5py/_objects.c:2804)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5g.pyx\u001b[0m in \u001b[0;36mh5py.h5g.GroupID.get_num_objs (/home/ilan/minonda/conda-bld/h5py_1496871545397/work/h5py/h5g.c:4395)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Not a location id (Invalid object id)"
     ]
    }
   ],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"/scratch/yang/aws_data/CIL_modular_data/_benchmarks_results/mm45_v4_base_newseg_YangExp_Town02/metrics.json\"\n",
    "import json\n",
    "obj=json.load(open(path, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'intersection_otherlane',\n",
       " u'intersection_offroad',\n",
       " u'collision_other',\n",
       " u'driven_kilometers',\n",
       " u'collision_pedestrians',\n",
       " u'average_speed',\n",
       " u'episodes_fully_completed',\n",
       " u'episodes_completion',\n",
       " u'collision_vehicles']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj['episodes_fully_completed'].keys()\n",
    "t = obj['episodes_fully_completed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train', ' weather ', '1.0', ' task ', 0, ' average performance ', 0.6, '(num sample 15)')\n",
      "('train', ' weather ', '1.0', ' task ', 1, ' average performance ', 0.72, '(num sample 25)')\n",
      "('train', ' weather ', '10.0', ' task ', 0, ' average performance ', 0.8666666666666667, '(num sample 15)')\n",
      "('train', ' weather ', '10.0', ' task ', 1, ' average performance ', 0.88, '(num sample 25)')\n",
      "('val', ' weather ', '13.0', ' task ', 0, ' average performance ', 0.7333333333333333, '(num sample 15)')\n",
      "('val', ' weather ', '13.0', ' task ', 1, ' average performance ', 0.11764705882352941, '(num sample 17)')\n",
      "('val', ' weather ', '14.0', ' task ', 0, ' average performance ', 0.0, '(num sample 0)')\n",
      "('val', ' weather ', '14.0', ' task ', 1, ' average performance ', 0.8, '(num sample 15)')\n"
     ]
    }
   ],
   "source": [
    "weathers = {\"train\": [\"1.0\", \"10.0\"],\n",
    "           \"val\": [\"13.0\", \"14.0\"]}\n",
    "for phase in [\"train\", \"val\"]:\n",
    "    for weather in weathers[phase]:\n",
    "        for task in range(len(t[weather])):\n",
    "            perf = np.mean(t[weather][task])\n",
    "            try:\n",
    "                nsample = len(t[weather][task])\n",
    "            except TypeError:\n",
    "                nsample = 0\n",
    "            \n",
    "            print(phase, \" weather \", weather, \" task \", task, \" average performance \", perf, \"(num sample %d)\" % nsample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./drive_interfaces/carla/carla_client/carla/driving_benchmark/experiment_suites/\")\n",
    "\n",
    "import experiment_suite\n",
    "class YangExp(experiment_suite.ExperimentSuite):\n",
    "\n",
    "    def set_train_weathers(self, weathers):\n",
    "        self.train_weathers_data = weathers\n",
    "\n",
    "    @property\n",
    "    def train_weathers(self):\n",
    "        return self.train_weathers_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = YangExp(\"Town01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.set_train_weathers([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.train_weathers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# To be redefined on subclasses on how to calculate timeout for an episode\r\n",
      "import abc\r\n",
      "\r\n",
      "\r\n",
      "class ExperimentSuite(object):\r\n",
      "\r\n",
      "    def __init__(self, city_name):\r\n",
      "\r\n",
      "        self._city_name = city_name\r\n",
      "        self._experiments = self.build_experiments()\r\n",
      "\r\n",
      "    def calculate_time_out(self, path_distance):\r\n",
      "        \"\"\"\r\n",
      "        Function to return the timeout ,in milliseconds,\r\n",
      "        that is calculated based on distance to goal.\r\n",
      "        This is the same timeout as used on the CoRL paper.\r\n",
      "        \"\"\"\r\n",
      "        return 8*(((path_distance / 1000.0) / 10.0) * 3600.0 + 500010.0)\r\n",
      "\r\n",
      "    def get_number_of_poses_task(self):\r\n",
      "        \"\"\"\r\n",
      "            Get the number of poses a task have for this benchmark\r\n",
      "        \"\"\"\r\n",
      "\r\n",
      "        # Warning: assumes that all tasks have the same size\r\n",
      "\r\n",
      "        return len(self._experiments[0].poses)\r\n",
      "\r\n",
      "    def get_experiments(self):\r\n",
      "        \"\"\"\r\n",
      "        Getter for the experiment set.\r\n",
      "        \"\"\"\r\n",
      "        return self._experiments\r\n",
      "\r\n",
      "    @property\r\n",
      "    def dynamic_tasks(self):\r\n",
      "        \"\"\"\r\n",
      "        Returns the episodes that contain dynamic obstacles\r\n",
      "        \"\"\"\r\n",
      "        dynamic_tasks = set()\r\n",
      "        for exp in self._experiments:\r\n",
      "            if exp.conditions.NumberOfVehicles > 0 or exp.conditions.NumberOfPedestrians > 0:\r\n",
      "                dynamic_tasks.add(exp.task)\r\n",
      "\r\n",
      "        return list(dynamic_tasks)\r\n",
      "\r\n",
      "    @property\r\n",
      "    def metrics_parameters(self):\r\n",
      "        \"\"\"\r\n",
      "        Property to return the parameters for the metric module\r\n",
      "        Could be redefined depending on the needs of the user.\r\n",
      "        \"\"\"\r\n",
      "        return {\r\n",
      "\r\n",
      "            'intersection_offroad': {'frames_skip': 10,\r\n",
      "                                     'frames_recount': 20,\r\n",
      "                                     'threshold': 0.3\r\n",
      "                                     },\r\n",
      "            'intersection_otherlane': {'frames_skip': 10,\r\n",
      "                                       'frames_recount': 20,\r\n",
      "                                       'threshold': 0.4\r\n",
      "                                       },\r\n",
      "            'collision_other': {'frames_skip': 10,\r\n",
      "                                'frames_recount': 20,\r\n",
      "                                'threshold': 400\r\n",
      "                                },\r\n",
      "            'collision_vehicles': {'frames_skip': 10,\r\n",
      "                                   'frames_recount': 30,\r\n",
      "                                   'threshold': 400\r\n",
      "                                   },\r\n",
      "            'collision_pedestrians': {'frames_skip': 5,\r\n",
      "                                      'frames_recount': 100,\r\n",
      "                                      'threshold': 300\r\n",
      "                                      },\r\n",
      "\r\n",
      "        }\r\n",
      "\r\n",
      "    @property\r\n",
      "    def weathers(self):\r\n",
      "        weathers = set(self.train_weathers)\r\n",
      "        weathers.update(self.test_weathers)\r\n",
      "        return weathers\r\n",
      "\r\n",
      "    @abc.abstractmethod\r\n",
      "    def build_experiments(self):\r\n",
      "        \"\"\"\r\n",
      "        Returns a set of experiments to be evaluated\r\n",
      "        Must be redefined in an inherited class.\r\n",
      "\r\n",
      "        \"\"\"\r\n",
      "\r\n",
      "    \r\n",
      "    def train_weathers(self):\r\n",
      "        \"\"\"\r\n",
      "        Return the weathers that are considered as training conditions\r\n",
      "        \"\"\"\r\n",
      "        return None\r\n",
      "\r\n",
      "    @abc.abstractproperty\r\n",
      "    def test_weathers(self):\r\n",
      "        \"\"\"\r\n",
      "        Return the weathers that are considered as testing conditions\r\n",
      "        \"\"\"\r\n"
     ]
    }
   ],
   "source": [
    "!cat ./drive_interfaces/carla/carla_client/carla/driving_benchmark/experiment_suites/experiment_suite.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
